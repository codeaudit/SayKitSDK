{"name":"SayKit SDK","tagline":"Framework for building voice enabled applications on iOS","body":"# SayKit SDK (Developer Preview)\r\nThe conversational UI framework for voice enabled applications on iOS.\r\n\r\n**Current version: 0.8.0**\r\n\r\nWe're excited to offer a preview of the SayKit framework as we prepare it for production release. Though we're still rolling out a couple features, streamlining some APIs, and sprucing up our docs, it's fully ready for use today.\r\n\r\nSince we're actively iterating as we march to version 1.0, the SDK will be frequently updated with new features.\r\n\r\nWe are eager to hear your thoughts or feedback. Please drop us a line at [info@saykit.org](mailto:info@saykit.org). Also, please post any bugs in our [Github issue tracker](https://github.com/ConversantLabs/SayKitSDK/issues).\r\n\r\n## <a name=\"developer-resources\"></a> Developer Resources\r\n\r\nWhat are you looking to do?\r\n\r\n- **Jump in**: [Installation guide](#installation-guide)\r\n- **Familiarize yourself**: [SayKit tour](https://github.com/ConversantLabs/SayKitSDK/blob/master/Tour/00-intro.md)\r\n- **Learn by doing**: [Step-by-step tutorial](#) *(coming soon)*\r\n- **Read the headers**: [API documentation](https://github.com/ConversantLabs/SayKitSDK/blob/master/API Reference/html/)\r\n- **Go deep**: [In-depth Developer guides](#) *(coming soon)*\r\n- **Glimpse the future**: [Feature roadmap](#) *(coming soon)*\r\n\r\n## <a name=\"installation-guide\"></a> Installation Guide\r\n\r\n### 1. Download the SDK\r\n\r\nDownload the SayKit SDK [here](https://github.com/ConversantLabs/SayKitSDK/archive/master.zip).\r\n\r\n### 2. Add the SayKit framework to your project\r\n\r\n- In Xcode, File -> Add Files to \"Project\".\r\n- Navigate to where you downloaded the framework, and select `SayKitSDK.framework`. The framework should now appear on the left, in Xcode's Project Navigator pane.\r\n- Select the project in the Navigator pane, select your target, and go to the Build Phases tab.\r\n- Under \"Link Binary With Libraries\", make sure `SayKitSDK.framework` is in the list.\r\n- Under \"Embed Frameworks\", make sure `SayKitSDK.framework` is in the list.\r\n- If using Swift, create a bridging header that includes `<SayKit/SayKit.h>`. See [Apple's guide on Importing Objective-C into Swift](https://developer.apple.com/library/ios/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html#//apple_ref/doc/uid/TP40014216-CH10-ID156) for more details.\r\n\r\n*// TODO: add Xcode screenshots/video*\r\n\r\n### 3. Configure the Conversation Manager\r\n\r\nThe conversation manager provides the foundation for SayKit's integration with your application code.\r\n\r\n> If this is the first you're hearing about a so-called \"Conversation Manager\", you need to stop and learn a bit more about SayKit! [Take a look at our developer resources](#developer-resources).\r\n\r\nEach SayKit app has a default manager ready and waiting, accessibile as `[SAYConversationManager systemManager]`. A typical app will require two pieces of configuration on this manager:\r\n\r\n1. An audio event source (conforming to the `SAYAudioEventSource` protocol). This provides an outlet for audible events (e.g. speech, sound effects) to be presented to the user. These are \r\n2. A command registry (conforming to the `SAYVerbalCommandRegistry` protocol). This provides SayKit's speech recognition systems with a set of command recognizers.\r\n\r\nThe particular configuration you'll want will depend on your application's needs, but as a simple example, let's set up the manager to use a simple flat command recognizer catalog (`SAYCommandRecognizerCatalog`) and sound board (`SAYSoundBoard`) on the main audio track.\r\n\r\nObjective-C:\r\n````objc\r\nSAYCommandRecognizerCatalog *catalog = [[SAYCommandRecognizerCatalog alloc] init];\r\n[[SAYConversationManager systemManager] addAudioSource:soundBoard forTrack:SAYAudioTrackMainIdentifier];\r\n\r\nSAYSoundBoard *soundBoard = [[SAYSoundBoard alloc] init];\r\n[[SAYConversationManager systemManager] setCommandRegistry:catalog];\r\n````\r\n\r\nSwift:\r\n````swift\r\nlet catalog = SAYCommandRecognizerCatalog()\r\nSAYConversationManager.systemManager().commandRegistry = catalog\r\n\r\nlet soundBoard = SAYSoundBoard()\r\nSAYConversationManager.systemManager().addAudioSource(soundBoard, forTrack:SAYAudioTrackMainIdentifier)\r\n````\r\n\r\nTypically, this configuration would go in your AppDelegate's `application:didFinishLaunchingWithOptions:` method.\r\n\r\n### 4. Go!\r\n\r\nNow you're all ready to go!\r\n\r\nAdd voice commands to your Todo list app. Make your RSS app read the news aloud. Create a chat bot friend. The sky's the limit.\r\n\r\nNow, if you are looking for a bit more help on where to go next: [check out our developer resources](#developer-resources).","google":" UA-62598307-3","note":"Don't delete this file! It's used internally to help with page regeneration."}